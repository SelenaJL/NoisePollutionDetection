{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named librosa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d9afef9d8a40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named librosa"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import metrics\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import librosa.display\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import math\n",
    "\n",
    "# to run this code, you'll need to load the following data:\n",
    "# train_x, train_y\n",
    "# valid_x, valid_y\n",
    "# test_x, test_y\n",
    "# see http://aqibsaeed.github.io/2016-09-24-urban-sound-classification-part-2/ for details\n",
    "\n",
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += (window_size / 2)\n",
    "\n",
    "def extract_features(parent_dir,sub_dirs,file_ext=\"*.wav\",bands = 60, frames = 41):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    log_specgrams = []\n",
    "    labels = []\n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            sound_clip,s = librosa.load(fn)\n",
    "            label = fn.split('/')[2].split('-')[1]\n",
    "            for (start,end) in windows(sound_clip,window_size):\n",
    "                if(len(sound_clip[start:end]) == window_size):\n",
    "                    signal = sound_clip[start:end]\n",
    "                    melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "                    logspec = librosa.logamplitude(melspec)\n",
    "                    logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "                    log_specgrams.append(logspec)\n",
    "                    labels.append(label)\n",
    "\n",
    "    log_specgrams = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis = 3)\n",
    "    for i in range(len(features)):\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "\n",
    "    return np.array(features), np.array(labels,dtype = np.int)\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode\n",
    "\n",
    "parent_dir = 'UrbanSound'\n",
    "tr_sub_dirs = [\"fold1test\",\"fold2test\"]\n",
    "tr_features,tr_labels = extract_features(parent_dir,tr_sub_dirs)\n",
    "#tr_labels = one_hot_encode(tr_labels)\n",
    "tr_labels = to_categorical(tr_labels,num_classes=10)\n",
    "train_x = tr_features\n",
    "train_y = tr_labels\n",
    "\n",
    "\n",
    "vl_sub_dirs = [\"fold1test\",\"fold2test\"]\n",
    "vl_features,vl_labels = extract_features(parent_dir,vl_sub_dirs)\n",
    "#vl_labels = one_hot_encode(vl_labels)\n",
    "vl_labels = to_categorical(vl_labels,num_classes=10)\n",
    "val_x = vl_features\n",
    "val_y = vl_labels\n",
    "\n",
    "ts_sub_dirs= ['fold3']\n",
    "ts_features,ts_labels = extract_features(parent_dir,ts_sub_dirs)\n",
    "#ts_labels = one_hot_encode(ts_labels)\n",
    "ts_labels = to_categorical(ts_labels,num_classes=10)\n",
    "test_x = ts_features\n",
    "test_y = ts_labels\n",
    "\n",
    "# data dimension parameters\n",
    "frames = 41\n",
    "bands = 60\n",
    "num_channels = 2\n",
    "num_labels = test_y.shape[1]\n",
    "\n",
    "# start by creating a linear stack of layers\n",
    "model = Sequential()\n",
    "\n",
    "# will use filters of size 2x2\n",
    "f_size = 2\n",
    "\n",
    "# first layer applies 32 convolution filters\n",
    "# input: 60x41 data frames with 2 channels => (60,41,2) tensors\n",
    "model.add(Convolution2D(32, f_size, f_size, border_mode='same', input_shape=(bands, frames, num_channels)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, f_size, f_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "# next layer applies 64 convolution filters\n",
    "model.add(Convolution2D(64, f_size, f_size, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, f_size, f_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# flatten output into a single dimension\n",
    "# Keras will do the shape inference automatically\n",
    "model.add(Flatten())\n",
    "\n",
    "# then a fully connected NN layer\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# finally, an output layer with one node per class\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# use the Adam optimiser\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# now compile the model, Keras will take care of the Tensorflow boilerplate\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(type(train_x.shape))\n",
    "print(type(train_y.shape))\n",
    "print(train_x)\n",
    "print(train_y)\n",
    "# for quicker training, just using one epoch, you can experiment with more\n",
    "model.fit(train_x, train_y, validation_data=(val_x, val_y), batch_size=32, nb_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
